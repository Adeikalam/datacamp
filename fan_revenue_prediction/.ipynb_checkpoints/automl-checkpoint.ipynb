{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "import unidecode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeik\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (4,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304098, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from problem import get_train_data\n",
    "\n",
    "X_df, y_array = get_train_data()\n",
    "\n",
    "# keeping first 2 numbers of APE\n",
    "t = time.time()\n",
    "X_df['Activity_code (APE)'] = X_df['Activity_code (APE)'].fillna(value = '00').astype('str').apply(lambda x: x[:2])\n",
    "\n",
    "# infer zipcode from city\n",
    "\n",
    "if(True):\n",
    "    X_df['Zipcode'] = X_df['Zipcode'].astype('str').apply(lambda x: x[:2])\n",
    "    city_names = X_df[['Zipcode', 'City']].groupby('Zipcode').City.apply(list).values\n",
    "    zipcodes = X_df[['Zipcode', 'City']].groupby('Zipcode').City.apply(list).index\n",
    "    zip_dict = {zipcode:list(set(cities)) for zipcode,cities in zip(zipcodes, city_names)}\n",
    "    \n",
    "    #remove nans from city lists\n",
    "    \n",
    "    for key in zip_dict.keys():\n",
    "        for i, city in enumerate(zip_dict[key]):\n",
    "            if type(city) != type('a string'):\n",
    "                zip_dict[key].pop(i)\n",
    "           \n",
    "    # infer zip by checking lists\n",
    "    \n",
    "    def infer_zip(city):\n",
    "        for key in zip_dict:\n",
    "            if city in zip_dict[key]:\n",
    "                return key\n",
    "    \n",
    "    X_df.loc[X_df['Zipcode'] == 'na', 'Zipcode'] = X_df.loc[X_df['Zipcode'] == 'na', 'City'].apply(infer_zip)\n",
    "    X_df.loc[X_df['Zipcode'] == 'na', 'Zipcode'] = '00'\n",
    "    X_df['Zipcode'] = X_df['Zipcode'].fillna('00')\n",
    "    \n",
    "# fill name and lower\n",
    "\n",
    "X_df['Name'] = X_df['Name'].fillna('nan').str.lower().astype('str').apply(unidecode.unidecode)\n",
    "\n",
    "# Fill headcounts\n",
    "\n",
    "if(True):\n",
    "    headcounts = X_df[['Name', 'Headcount']].groupby('Name').mean().fillna(0).to_dict()['Headcount']\n",
    "    names = X_df['Name'].values\n",
    "    heads = np.zeros(len(names))\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        if type(name) == type('a string'):\n",
    "            heads[i] = headcounts[name]\n",
    "\n",
    "    X_df['Headcount'] = heads\n",
    "\n",
    "# unicode and lower\n",
    "\n",
    "X_df['City'] = X_df['City'].fillna('nan').str.lower().apply(unidecode.unidecode)\n",
    "\n",
    "# Drop Address\n",
    "\n",
    "award = pd.read_csv('data/award_notices_RAMP.csv.zip', compression='zip')\n",
    "\n",
    "city_list = [unidecode.unidecode(i.lower()) for i in list(set(X_df['City'].values))]\n",
    "\n",
    "def cedex_remover(s):\n",
    "    s = s.replace('-', ' ').replace(',', ' ')\n",
    "    tokens = s.split(' ')\n",
    "    for k in range(len(tokens)):\n",
    "        for j in range(1, len(tokens)-k + 1):\n",
    "            if ' '.join(tokens[k:k+j]) in city_list:\n",
    "                return ' '.join(tokens[k:k+j])\n",
    "    return None\n",
    "\n",
    "award.head(3)\n",
    "\n",
    "print(award.shape)\n",
    "\n",
    "# unidecode incumbent_name and lower\n",
    "\n",
    "award['incumbent_name'] = award['incumbent_name'].str.lower().astype('str').apply(unidecode.unidecode)\n",
    "\n",
    "# preprocess incumbent_city and fill nans\n",
    "award['incumbent_city'] = award['incumbent_city'].str.lower().astype('str').apply(unidecode.unidecode).apply(cedex_remover).fillna('nan')\n",
    "\n",
    "\n",
    "# Remove NA in department of provision and keep first 2\n",
    "award = award[award['Departments_of_publication'].notna()]\n",
    "award['Departments_of_publication'] = award['Departments_of_publication'].astype('str').apply(lambda x: x.split(',')[0][:2])\n",
    "\n",
    "\n",
    "# city mean FAN\n",
    "\n",
    "city_mean_fan = award[['incumbent_city','amount']].groupby('incumbent_city').quantile(0.5).fillna(0).to_dict()['amount']\n",
    "\n",
    "city_lower_mean = award[['incumbent_city','amount']].groupby('incumbent_city').quantile(0.25).fillna(0).to_dict()['amount']\n",
    "city_higher_mean = award[['incumbent_city','amount']].groupby('incumbent_city').quantile(0.75).fillna(0).to_dict()['amount']\n",
    "\n",
    "# zip mean FAN\n",
    "\n",
    "zip_mean_fan = award[['Departments_of_publication','amount']].groupby('Departments_of_publication').quantile(0.5).fillna(0).to_dict()['amount']\n",
    "\n",
    "zip_lower_mean = award[['Departments_of_publication','amount']].groupby('Departments_of_publication').quantile(0.25).fillna(0).to_dict()['amount']\n",
    "zip_higher_mean = award[['Departments_of_publication','amount']].groupby('Departments_of_publication').quantile(0.75).fillna(0).to_dict()['amount']\n",
    "\n",
    "\n",
    "# APE mean FAN\n",
    "company_list = [unidecode.unidecode(str(i).lower()) for i in list(set(X_df['Name'].values))]\n",
    "\n",
    "company_awards = award[award['incumbent_name'].isin(company_list)]\n",
    "\n",
    "ape_companies = X_df[['Name', 'Activity_code (APE)']].groupby('Name')['Activity_code (APE)'].apply(lambda x: list(x)[0])\n",
    "ape_companies.index = ape_companies.index.str.lower()\n",
    "ape_companies = ape_companies.to_dict()\n",
    "\n",
    "def infer_ape(name):\n",
    "    return ape_companies[name]\n",
    "company_awards['APE'] = company_awards['incumbent_name'].apply(infer_ape)\n",
    "\n",
    "ape_mean_fan = company_awards[['APE','amount']].groupby('APE').quantile(0.5).fillna(0).to_dict()['amount']\n",
    "ape_lower_mean = company_awards[['APE','amount']].groupby('APE').quantile(0.25).fillna(0).to_dict()['amount']\n",
    "ape_higher_mean = company_awards[['APE','amount']].groupby('APE').quantile(0.75).fillna(0).to_dict()['amount']\n",
    "\n",
    "# Actual FAN revenue\n",
    "\n",
    "fan_revenue = company_awards[['incumbent_name','amount']].groupby('incumbent_name').sum().fillna(0).to_dict()['amount']\n",
    "\n",
    "# Insert features into X_df\n",
    "\n",
    "# Ape FAN\n",
    "if(True):\n",
    "    def infer_ape_fan(APE):\n",
    "        try:\n",
    "            return ape_mean_fan[APE]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_low_ape_fan(APE):\n",
    "        try:\n",
    "            return ape_lower_mean[APE]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_high_ape_fan(APE):\n",
    "        try:\n",
    "            return ape_higher_mean[APE]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "\n",
    "    X_df['APE_fan_0.5'] = X_df['Activity_code (APE)'].apply(infer_ape_fan)\n",
    "    X_df['APE_fan_0.25'] = X_df['Activity_code (APE)'].apply(infer_low_ape_fan)\n",
    "    X_df['APE_fan_0.75'] = X_df['Activity_code (APE)'].apply(infer_high_ape_fan)\n",
    "\n",
    "# City FAN\n",
    "if(True):\n",
    "\n",
    "    def infer_city_fan(city):\n",
    "        try:\n",
    "            return city_mean_fan[city]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_low_city_fan(city):\n",
    "        try:\n",
    "            return city_lower_mean[city]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_high_city_fan(city):\n",
    "        try:\n",
    "            return city_higher_mean[city]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    X_df['city_fan_0.5'] = X_df['City'].apply(infer_city_fan)\n",
    "    X_df['city_fan_0.25'] = X_df['City'].apply(infer_low_city_fan)\n",
    "    X_df['city_fan_0.75'] = X_df['City'].apply(infer_high_city_fan)\n",
    "\n",
    "# Zip_fan\n",
    "if(True):\n",
    "    def infer_zip_fan(zipcode):\n",
    "        try:\n",
    "            return zip_mean_fan[zipcode]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_low_zip_fan(zipcode):\n",
    "        try:\n",
    "            return zip_lower_mean[zipcode]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def infer_high_zip_fan(zipcode):\n",
    "        try:\n",
    "            return zip_higher_mean[zipcode]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    X_df['zip_fan_0.5'] = X_df['Zipcode'].apply(infer_zip_fan)\n",
    "    X_df['zip_fan_0.25'] = X_df['Zipcode'].apply(infer_low_zip_fan)\n",
    "    X_df['zip_fan_0.75'] = X_df['Zipcode'].apply(infer_high_zip_fan)\n",
    "\n",
    "# Actual FAN\n",
    "if(True):\n",
    "    def infer_fan(name):\n",
    "        try:\n",
    "            return fan_revenue[name]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    X_df['FAN'] = X_df['Name'].apply(infer_fan)\n",
    "\n",
    "\n",
    "to_dummy = ['Activity_code (APE)', 'Zipcode', 'Year']\n",
    "to_drop = ['Name', 'Address', 'City', 'Fiscal_year_end_date']\n",
    "X_df = X_df.drop(to_drop, axis = 1)\n",
    "X_df['y'] = y_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binascii import crc32\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test = split_train_test_by_id(X_df, 0.2, 'Legal_ID')\n",
    "#y_train = X_train['y']\n",
    "X_train = X_train.drop(['Legal_ID'], axis = 1)\n",
    "\n",
    "#y_test = X_test['y']\n",
    "X_test = X_test.drop(['Legal_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['y'].to_numpy()\n",
    "\n",
    "X_train['y'] = np.max(np.array([np.ones(y_train.shape[0]), y_train]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_ml import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "You are running on version 2.9.9\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{}\n",
      "Running basic data cleaning\n",
      "Performing feature scaling\n",
      "Fitting DataFrameVectorizer\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to run GridSearchCV on the pipeline for several models to predict y\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  7.0min remaining: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:  8.3min remaining:  5.0min\n"
     ]
    }
   ],
   "source": [
    "column_descriptions = {\n",
    "    'y': 'output',\n",
    "    'Activity_code (APE)': 'categorical',\n",
    "    'Zipcode': 'categorical',\n",
    "    'Year': 'categorical'\n",
    "}\n",
    "\n",
    "ml_predictor = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n",
    "\n",
    "ml_predictor.train(X_train, take_log_of_y = True, cv = 2,\n",
    "                   model_names = ['Lasso', 'GradientBoostingRegressor', 'Ridge', 'XGBRegressor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "***********************************************\n",
      "Advanced scoring metrics for the trained regression model on this particular dataset:\n",
      "\n",
      "Here is the overall RMSE for these predictions:\n",
      "154563957.6686752\n",
      "\n",
      "Here is the average of the predictions:\n",
      "4735235.04601938\n",
      "\n",
      "Here is the average actual value on this validation set:\n",
      "4414034.472833534\n",
      "\n",
      "Here is the median prediction:\n",
      "1289948.25\n",
      "\n",
      "Here is the median actual value:\n",
      "289764.0\n",
      "\n",
      "Here is the mean absolute error:\n",
      "5026571.382249614\n",
      "\n",
      "Here is the median absolute error (robust to outliers):\n",
      "1078972.375\n",
      "\n",
      "Here is the explained variance:\n",
      "0.3129601247344025\n",
      "\n",
      "Here is the R-squared value:\n",
      "0.3129571577177511\n",
      "Count of positive differences (prediction > actual):\n",
      "254959\n",
      "Count of negative differences:\n",
      "44988\n",
      "Average positive difference:\n",
      "3145698.239161983\n",
      "Average negative difference:\n",
      "-15685981.351318685\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-154563957.6686752"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_predictor.score(X_test, X_test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "You are running on version 2.9.9\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'presort': False, 'learning_rate': 0.1, 'warm_start': True}\n",
      "Running basic data cleaning\n",
      "Fitting DataFrameVectorizer\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'presort': False, 'learning_rate': 0.1, 'warm_start': True}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model GradientBoostingRegressor to predict y\n",
      "Started at:\n",
      "2019-11-28 03:57:45\n",
      "[1] random_holdout_set_from_training_data's score is: -2.865\n",
      "[2] random_holdout_set_from_training_data's score is: -2.804\n",
      "[3] random_holdout_set_from_training_data's score is: -2.751\n",
      "[4] random_holdout_set_from_training_data's score is: -2.707\n",
      "[5] random_holdout_set_from_training_data's score is: -2.67\n",
      "[6] random_holdout_set_from_training_data's score is: -2.639\n",
      "[7] random_holdout_set_from_training_data's score is: -2.613\n",
      "[8] random_holdout_set_from_training_data's score is: -2.59\n",
      "[9] random_holdout_set_from_training_data's score is: -2.572\n",
      "[10] random_holdout_set_from_training_data's score is: -2.556\n",
      "[11] random_holdout_set_from_training_data's score is: -2.542\n",
      "[12] random_holdout_set_from_training_data's score is: -2.531\n",
      "[13] random_holdout_set_from_training_data's score is: -2.521\n",
      "[14] random_holdout_set_from_training_data's score is: -2.512\n",
      "[15] random_holdout_set_from_training_data's score is: -2.505\n",
      "[16] random_holdout_set_from_training_data's score is: -2.498\n",
      "[17] random_holdout_set_from_training_data's score is: -2.492\n",
      "[18] random_holdout_set_from_training_data's score is: -2.488\n",
      "[19] random_holdout_set_from_training_data's score is: -2.483\n",
      "[20] random_holdout_set_from_training_data's score is: -2.479\n",
      "[21] random_holdout_set_from_training_data's score is: -2.476\n",
      "[22] random_holdout_set_from_training_data's score is: -2.473\n",
      "[23] random_holdout_set_from_training_data's score is: -2.468\n",
      "[24] random_holdout_set_from_training_data's score is: -2.466\n",
      "[25] random_holdout_set_from_training_data's score is: -2.462\n",
      "[26] random_holdout_set_from_training_data's score is: -2.46\n",
      "[27] random_holdout_set_from_training_data's score is: -2.458\n",
      "[28] random_holdout_set_from_training_data's score is: -2.456\n",
      "[29] random_holdout_set_from_training_data's score is: -2.453\n",
      "[30] random_holdout_set_from_training_data's score is: -2.451\n",
      "[31] random_holdout_set_from_training_data's score is: -2.448\n",
      "[32] random_holdout_set_from_training_data's score is: -2.446\n",
      "[33] random_holdout_set_from_training_data's score is: -2.444\n",
      "[34] random_holdout_set_from_training_data's score is: -2.442\n",
      "[35] random_holdout_set_from_training_data's score is: -2.441\n",
      "[36] random_holdout_set_from_training_data's score is: -2.44\n",
      "[37] random_holdout_set_from_training_data's score is: -2.438\n",
      "[38] random_holdout_set_from_training_data's score is: -2.437\n",
      "[39] random_holdout_set_from_training_data's score is: -2.436\n",
      "[40] random_holdout_set_from_training_data's score is: -2.434\n",
      "[41] random_holdout_set_from_training_data's score is: -2.433\n",
      "[42] random_holdout_set_from_training_data's score is: -2.432\n",
      "[43] random_holdout_set_from_training_data's score is: -2.43\n",
      "[44] random_holdout_set_from_training_data's score is: -2.429\n",
      "[45] random_holdout_set_from_training_data's score is: -2.428\n",
      "[46] random_holdout_set_from_training_data's score is: -2.428\n",
      "[47] random_holdout_set_from_training_data's score is: -2.427\n",
      "[48] random_holdout_set_from_training_data's score is: -2.425\n",
      "[49] random_holdout_set_from_training_data's score is: -2.424\n",
      "[50] random_holdout_set_from_training_data's score is: -2.423\n",
      "[52] random_holdout_set_from_training_data's score is: -2.422\n",
      "[54] random_holdout_set_from_training_data's score is: -2.42\n",
      "[56] random_holdout_set_from_training_data's score is: -2.419\n",
      "[58] random_holdout_set_from_training_data's score is: -2.417\n",
      "[60] random_holdout_set_from_training_data's score is: -2.416\n",
      "[62] random_holdout_set_from_training_data's score is: -2.415\n",
      "[64] random_holdout_set_from_training_data's score is: -2.414\n",
      "[66] random_holdout_set_from_training_data's score is: -2.413\n",
      "[68] random_holdout_set_from_training_data's score is: -2.412\n",
      "[70] random_holdout_set_from_training_data's score is: -2.411\n",
      "[72] random_holdout_set_from_training_data's score is: -2.411\n",
      "[74] random_holdout_set_from_training_data's score is: -2.41\n",
      "[76] random_holdout_set_from_training_data's score is: -2.409\n",
      "[78] random_holdout_set_from_training_data's score is: -2.408\n",
      "[80] random_holdout_set_from_training_data's score is: -2.407\n",
      "[82] random_holdout_set_from_training_data's score is: -2.406\n",
      "[84] random_holdout_set_from_training_data's score is: -2.405\n",
      "[86] random_holdout_set_from_training_data's score is: -2.404\n",
      "[88] random_holdout_set_from_training_data's score is: -2.403\n",
      "[90] random_holdout_set_from_training_data's score is: -2.403\n",
      "[92] random_holdout_set_from_training_data's score is: -2.402\n",
      "[94] random_holdout_set_from_training_data's score is: -2.401\n"
     ]
    }
   ],
   "source": [
    "column_descriptions = {\n",
    "    'y': 'output',\n",
    "    'Activity_code (APE)': 'categorical',\n",
    "    'Zipcode': 'categorical',\n",
    "    'Year': 'categorical'\n",
    "}\n",
    "\n",
    "ml_predictor2 = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n",
    "\n",
    "ml_predictor2.train(X_train, take_log_of_y = True, cv = 2,\n",
    "                   model_names = ['GradientBoostingRegressor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
